# 강의시작
- AI는 실험적 학문에 가까움. 언제든 바뀔 수 있다.

## 환경구성
```shell
poetry init
poetry config --local virtualenvs.in-project true
poetry env use python3.11
poetry install
# 활성화
poetry shell # poetry 1.x.x 버전
poetry env activate # poetry 2.x.x 버전
```



# 프로그램의 입력과 출력
## 1. 소프트웨어 1.0 : 입력 > 알고리즘 > 출력
- 장점 : 입력 <-> 관계가 명확하고 연산량이 작음.
- 단점 : 알고리즘으로 고안이 가능한 문제만 풀 수 있다.

## 2. 소프트웨어 2.0 : 입력 데이터 > ML 모델 > 출력
- 장점 : 사람이 알고리즘을 만들지 못하는 문제도 해결
- 단점 : 학습에 비용이 많이 소모된다.

3. 소프트웨어 3.0 : 프롬프트 > LLM > 출력
- 장점 : 하나의 모델로 다양한 기능.
- 단점 : 운영 비용이 크도, 의도한 출력이 아닐 수 있다.

## AI Factory
- perception > recognition > generation 단계로 넘어가고있고, 산업혁명의 공장의 역할을 할것.



# Deep learning
## ML vs deep learning
-  머신러닝에서는 모델 학습을 위해 feature를 뽑는 feature engineering이 필요하지만, 딥러닝에선 feature를 사람이 정의하지않는다. (representation learning)



# Attention machanism

## self attention
- input에 대해 attention을 주는것
eg) i ate an apple and an orange <-> i visited appple and google
apple이 orange와 나온다면 과일 apple
apple이 google과 나온다면 회사 apple

- similarity 계산을 위해 cosine distance를 사용한다. (연산량이 더 적으므로)

### query key value
- query : 이번 단어의 벡터
- key : 쿼리에 대한 각각 단어의 벡터
- value : 정보에 대한 각각의 단어의 벡터

```python

# Query, Key, Value 는 (약간의 비약을 하면) python dictionary와 비슷합니다.
info_dict = {
  ‘name’: ‘Kakao Corporation’, 
  ‘short_name’: ‘Kakao’, 
  ‘이름’: ‘카카오’, 
  ‘location’: ‘Jeju’
}
info_dict[query] = ?

# attention 에서는 ‘name’ 과 각각의 key (‘name’, ‘short_name’, ‘이름', ‘location’ 
# 유사도 값에 따라 유사도 값을 가중치로 하여 각각에 해당하는 value를 반환)

```

### multi head attention




## parallel processing
- qkv의 연산이 병렬로 실행된다.

## positional encoding
- 입력문장의 단어 순서에도 의미가 담겨있다!
eg) 나는 카리나를 좋아한다 <-> 카리나는 나를 좋아한다.
위는 같은 단어들의 조합으롬 만든 서로 다른 문장, 너무 다른 의미를 가지므로, input embedding에 대해서 순서를 기억하도록 한다.


# Language model








# 프롬프트 엔지니어링

- in context learning
- think step by step은 오피셜하게 거의 항상 성능이 높아진다.

## openai 의 프롬프트 엔지니어링 전략
1. Write clear instructions
2. Provide reference text
3. Split complex tasks into simpler subtasks
4. Give the model time to “think”
5. Use external tools
6. Test changes systematically


## chain of thought


## self consistency
LLM에게 어려운 테스크인경우

## least to most
- 문제를 쪼개고 순차적으로 푸는방법
- decomposition -> subproblem solving

### tree of thoughts
- 트리구조에 맞게 프롬프트를 준다.


### program of thought
- sudo 코드를 짜듯 넣어주면 더 잘 푼다.

### plan and solve
- CoT에서 step을 못하는 경우가 있고, 그것을 개선하기위한것.


### 예시
가장 먼저 풀어야 하는 태스크에 대한 알고리즘과 자료 구조에 대해 정리한 뒤,
아래 5가지 측면에서 프롬프트를 작성/개선
1. 보여줄 예시나 참고할 자료가 있나?
  a. few shot, web search, RAG
2. 활용할 논리나 구조가 있나? 
  a. CoT, ToT, Self consistency
3. 문제를 더 잘게 쪼갤 수 있나?
  a. least to most, plan and solve
4. 스스로 결과 검증할 수 있나?
  a. Self evaluation, self-redefine, chain of verification, system 2 attention etc.
5. 포맷
  a. JSON, HTML, Table, Chart etc.

