{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nETMGv52qGnB"
      },
      "outputs": [],
      "source": [
        "!pip install promptbench openai==1.3.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic_1os-LqKww",
        "outputId": "38d64978-e8b1-4696-fac8-9484020faeaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All supported datasets: \n",
            "['sst2', 'cola', 'qqp', 'mnli', 'mnli_matched', 'mnli_mismatched', 'qnli', 'wnli', 'rte', 'mrpc', 'mmlu', 'squad_v2', 'un_multi', 'iwslt2017', 'math', 'bool_logic', 'valid_parentheses', 'gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking', 'last_letter_concat', 'numersense', 'qasc', 'bbh', 'drop', 'arc-easy', 'arc-challenge']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading readme: 7.94kB [00:00, 3.65MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'content': \"Janetâ€™s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\",\n",
              "  'label': '18'},\n",
              " {'content': 'A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?',\n",
              "  'label': '3'},\n",
              " {'content': 'Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?',\n",
              "  'label': '70000'}]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import promptbench as pb\n",
        "\n",
        "# print all supported datasets in promptbench\n",
        "print('All supported datasets: ')\n",
        "print(pb.SUPPORTED_DATASETS)\n",
        "\n",
        "# load a dataset, sst2, for instance.\n",
        "# if the dataset is not available locally, it will be downloaded automatically.\n",
        "dataset_name = \"gsm8k\"\n",
        "dataset = pb.DatasetLoader.load_dataset(dataset_name)\n",
        "\n",
        "# print the first 3 examples\n",
        "dataset[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GboWIKBNwvnH",
        "outputId": "c0dc8535-0384-46e6-d1e7-616a38c1efe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All supported models: \n",
            "['google/flan-t5-large', 'llama2-7b', 'llama2-7b-chat', 'llama2-13b', 'llama2-13b-chat', 'llama2-70b', 'llama2-70b-chat', 'phi-1.5', 'phi-2', 'palm', 'gpt-3.5-turbo', 'gpt-4', 'gpt-4-1106-preview', 'gpt-3.5-turbo-1106', 'gpt-4-0125-preview', 'gpt-3.5-turbo-0125', 'gpt-4-turbo', 'gpt-4o', 'vicuna-7b', 'vicuna-13b', 'vicuna-13b-v1.3', 'google/flan-ul2', 'gemini-pro', 'mistralai/Mistral-7B-v0.1', 'mistralai/Mistral-7B-Instruct-v0.1', 'mistralai/Mixtral-8x7B-v0.1', 'mistralai/Mixtral-8x7B-Instruct-v0.1', '01-ai/Yi-6B', '01-ai/Yi-34B', '01-ai/Yi-6B-Chat', '01-ai/Yi-34B-Chat', 'baichuan-inc/Baichuan2-7B-Base', 'baichuan-inc/Baichuan2-13B-Base', 'baichuan-inc/Baichuan2-7B-Chat', 'baichuan-inc/Baichuan2-13B-Chat']\n"
          ]
        }
      ],
      "source": [
        "# print all supported models in promptbench\n",
        "print('All supported models: ')\n",
        "print(pb.SUPPORTED_MODELS)\n",
        "\n",
        "# load a model, gpt-3.5-turbo, for instance.\n",
        "# If model is openai/palm, need to provide openai_key/palm_key\n",
        "# If model is llama, vicuna, need to provide model dir\n",
        "model = pb.LLMModel(model='gpt-3.5-turbo',\n",
        "                    api_key = 'openai_key',\n",
        "                    max_new_tokens=150,\n",
        "                    device='mps'\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFPQRC6DtXQ4",
        "outputId": "67b43094-a8cd-41f0-980a-2c6e6498762a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All supported methods: \n",
            "['CoT', 'ZSCoT', 'least_to_most', 'generated_knowledge', 'expert_prompting', 'emotion_prompt', 'baseline']\n",
            "Supported datasets for each method: \n",
            "{'CoT': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'ZSCoT': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'expert_prompting': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'emotion_prompt': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'least_to_most': ['gsm8k', 'last_letter_concat'], 'generated_knowledge': ['csqa', 'numersense', 'qasc'], 'baseline': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking', 'last_letter_concat', 'numersense', 'qasc']}\n"
          ]
        }
      ],
      "source": [
        "# load method\n",
        "# print all methods and their supported datasets\n",
        "print('All supported methods: ')\n",
        "print(pb.SUPPORTED_METHODS)\n",
        "print('Supported datasets for each method: ')\n",
        "print(pb.METHOD_SUPPORT_DATASET)\n",
        "\n",
        "# load a method, emotion_prompt, for instance.\n",
        "# https://github.com/microsoft/promptbench/tree/main/promptbench/prompt_engineering\n",
        "method = pb.PEMethod(method='emotion_prompt',\n",
        "                        dataset=dataset_name,\n",
        "                        verbose=True,  # if True, print the detailed prompt and response\n",
        "                        prompt_id = 1  # for emotion_prompt\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.28.1\n"
          ]
        }
      ],
      "source": [
        "import httpx\n",
        "print(httpx.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAmaHUZCvqBT",
        "outputId": "4bcea33d-18c8-42d2-e81c-a06f5f9d0d75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1319 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Client.__init__() got an unexpected keyword argument 'proxies'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mmethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# if don't set the num_samples, method will use all examples in the dataset\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m results\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kakao/ai-advanced/sun.kist/.venv/lib/python3.11/site-packages/promptbench/prompt_engineering/__init__.py:77\u001b[39m, in \u001b[36mPEMethod.test\u001b[39m\u001b[34m(self, dataset, model, num_samples)\u001b[39m\n\u001b[32m     74\u001b[39m labels.append(label)\n\u001b[32m     76\u001b[39m input_text = data[\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m ouput = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer_method\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m res = re.findall(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m##(.*)\u001b[39m\u001b[33m'\u001b[39m, ouput)\n\u001b[32m     79\u001b[39m pred = res[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;28;01melse\u001b[39;00m ouput\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kakao/ai-advanced/sun.kist/.venv/lib/python3.11/site-packages/promptbench/prompt_engineering/emotion_prompt.py:44\u001b[39m, in \u001b[36mEmotionPrompt.query\u001b[39m\u001b[34m(self, input_text, model)\u001b[39m\n\u001b[32m     40\u001b[39m instr_get_answer = input_text + \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m + \u001b[38;5;28mself\u001b[39m.emotion_prompt + \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m + \\\n\u001b[32m     41\u001b[39m                    \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mPlease output your answer at the end as ##<your answer (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.output_range\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)>\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     42\u001b[39m prompt_get_answer = model.convert_text_to_prompt(instr_get_answer, \u001b[33m'\u001b[39m\u001b[33muser\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m answer = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_get_answer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mprint\u001b[39m(prompt_get_answer)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kakao/ai-advanced/sun.kist/.venv/lib/python3.11/site-packages/promptbench/models/__init__.py:174\u001b[39m, in \u001b[36mLLMModel.__call__\u001b[39m\u001b[34m(self, input_text, **kwargs)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_text, **kwargs):\n\u001b[32m    173\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Predicts the output based on the given input text using the loaded model.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kakao/ai-advanced/sun.kist/.venv/lib/python3.11/site-packages/promptbench/models/models.py:403\u001b[39m, in \u001b[36mOpenAIModel.predict\u001b[39m\u001b[34m(self, input_text, **kwargs)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_text, **kwargs):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopenai_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.system_prompt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    406\u001b[39m         system_messages = {\u001b[33m'\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant.\u001b[39m\u001b[33m\"\u001b[39m}\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kakao/ai-advanced/sun.kist/.venv/lib/python3.11/site-packages/openai/_client.py:107\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    105\u001b[39m     base_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://api.openai.com/v1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_strict_response_validation\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_strict_response_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28mself\u001b[39m._default_stream_cls = Stream\n\u001b[32m    120\u001b[39m \u001b[38;5;28mself\u001b[39m.completions = resources.Completions(\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kakao/ai-advanced/sun.kist/.venv/lib/python3.11/site-packages/openai/_base_client.py:760\u001b[39m, in \u001b[36mSyncAPIClient.__init__\u001b[39m\u001b[34m(self, version, base_url, max_retries, timeout, transport, proxies, limits, http_client, custom_headers, custom_query, _strict_response_validation)\u001b[39m\n\u001b[32m    745\u001b[39m         timeout = DEFAULT_TIMEOUT\n\u001b[32m    747\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    748\u001b[39m     version=version,\n\u001b[32m    749\u001b[39m     limits=limits,\n\u001b[32m   (...)\u001b[39m\u001b[32m    758\u001b[39m     _strict_response_validation=_strict_response_validation,\n\u001b[32m    759\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m760\u001b[39m \u001b[38;5;28mself\u001b[39m._client = http_client \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mhttpx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    761\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# cast to a valid type because mypy doesn't understand our type narrowing\u001b[39;49;00m\n\u001b[32m    763\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    764\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[38;5;28mself\u001b[39m._has_custom_http_client = \u001b[38;5;28mbool\u001b[39m(http_client)\n",
            "\u001b[31mTypeError\u001b[39m: Client.__init__() got an unexpected keyword argument 'proxies'"
          ]
        }
      ],
      "source": [
        "\n",
        "results = method.test(dataset,\n",
        "                      model,\n",
        "                      num_samples=3 # if don't set the num_samples, method will use all examples in the dataset\n",
        "                      )\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZaUgoBKvrvL",
        "outputId": "8b245892-3a09-4cba-e0e4-5a2c6d993b09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All supported methods: \n",
            "['CoT', 'ZSCoT', 'least_to_most', 'generated_knowledge', 'expert_prompting', 'emotion_prompt', 'baseline']\n",
            "Supported datasets for each method: \n",
            "{'CoT': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'ZSCoT': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'expert_prompting': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'emotion_prompt': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking'], 'least_to_most': ['gsm8k', 'last_letter_concat'], 'generated_knowledge': ['csqa', 'numersense', 'qasc'], 'baseline': ['gsm8k', 'csqa', 'bigbench_date', 'bigbench_object_tracking', 'last_letter_concat', 'numersense', 'qasc']}\n"
          ]
        }
      ],
      "source": [
        "# load method\n",
        "# print all methods and their supported datasets\n",
        "print('All supported methods: ')\n",
        "print(pb.SUPPORTED_METHODS)\n",
        "print('Supported datasets for each method: ')\n",
        "print(pb.METHOD_SUPPORT_DATASET)\n",
        "\n",
        "# load a method, emotion_prompt, for instance.\n",
        "# https://github.com/microsoft/promptbench/tree/main/promptbench/prompt_engineering\n",
        "method = pb.PEMethod(method='CoT',\n",
        "                        dataset=dataset_name,\n",
        "                        verbose=True,  # if True, print the detailed prompt and response\n",
        "                        prompt_id = 1  # for emotion_prompt\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-SQ6mqDyaS4",
        "outputId": "b9ef4414-d56c-4cf3-e16c-05d41c8f1d34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1319 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Client.__init__() got an unexpected keyword argument 'proxies'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mmethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# if don't set the num_samples, method will use all examples in the dataset\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m results\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kakao/ai-advanced/sun.kist/.venv/lib/python3.11/site-packages/promptbench/prompt_engineering/__init__.py:77\u001b[39m, in \u001b[36mPEMethod.test\u001b[39m\u001b[34m(self, dataset, model, num_samples)\u001b[39m\n\u001b[32m     74\u001b[39m labels.append(label)\n\u001b[32m     76\u001b[39m input_text = data[\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m ouput = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer_method\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m res = re.findall(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m##(.*)\u001b[39m\u001b[33m'\u001b[39m, ouput)\n\u001b[32m     79\u001b[39m pred = res[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;28;01melse\u001b[39;00m ouput\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kakao/ai-advanced/sun.kist/.venv/lib/python3.11/site-packages/promptbench/prompt_engineering/chain_of_thought.py:105\u001b[39m, in \u001b[36mCoT.query\u001b[39m\u001b[34m(self, input_text, model)\u001b[39m\n\u001b[32m    102\u001b[39m prompt_get_answer = model.convert_text_to_prompt(instr_get_answer, \u001b[33m'\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    103\u001b[39m prompt_get_answer = model.concat_prompts([prompt_question, prompt_get_answer])\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m answer = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_get_answer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mprint\u001b[39m(prompt_get_answer)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kakao/ai-advanced/sun.kist/.venv/lib/python3.11/site-packages/promptbench/models/__init__.py:174\u001b[39m, in \u001b[36mLLMModel.__call__\u001b[39m\u001b[34m(self, input_text, **kwargs)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_text, **kwargs):\n\u001b[32m    173\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Predicts the output based on the given input text using the loaded model.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kakao/ai-advanced/sun.kist/.venv/lib/python3.11/site-packages/promptbench/models/models.py:403\u001b[39m, in \u001b[36mOpenAIModel.predict\u001b[39m\u001b[34m(self, input_text, **kwargs)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_text, **kwargs):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopenai_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.system_prompt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    406\u001b[39m         system_messages = {\u001b[33m'\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant.\u001b[39m\u001b[33m\"\u001b[39m}\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kakao/ai-advanced/sun.kist/.venv/lib/python3.11/site-packages/openai/_client.py:107\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    105\u001b[39m     base_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://api.openai.com/v1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_strict_response_validation\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_strict_response_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28mself\u001b[39m._default_stream_cls = Stream\n\u001b[32m    120\u001b[39m \u001b[38;5;28mself\u001b[39m.completions = resources.Completions(\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kakao/ai-advanced/sun.kist/.venv/lib/python3.11/site-packages/openai/_base_client.py:760\u001b[39m, in \u001b[36mSyncAPIClient.__init__\u001b[39m\u001b[34m(self, version, base_url, max_retries, timeout, transport, proxies, limits, http_client, custom_headers, custom_query, _strict_response_validation)\u001b[39m\n\u001b[32m    745\u001b[39m         timeout = DEFAULT_TIMEOUT\n\u001b[32m    747\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    748\u001b[39m     version=version,\n\u001b[32m    749\u001b[39m     limits=limits,\n\u001b[32m   (...)\u001b[39m\u001b[32m    758\u001b[39m     _strict_response_validation=_strict_response_validation,\n\u001b[32m    759\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m760\u001b[39m \u001b[38;5;28mself\u001b[39m._client = http_client \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mhttpx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    761\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# cast to a valid type because mypy doesn't understand our type narrowing\u001b[39;49;00m\n\u001b[32m    763\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    764\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[38;5;28mself\u001b[39m._has_custom_http_client = \u001b[38;5;28mbool\u001b[39m(http_client)\n",
            "\u001b[31mTypeError\u001b[39m: Client.__init__() got an unexpected keyword argument 'proxies'"
          ]
        }
      ],
      "source": [
        "results = method.test(dataset,\n",
        "                      model,\n",
        "                      num_samples=3 # if don't set the num_samples, method will use all examples in the dataset\n",
        "                      )\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOWlobl4ybyz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
